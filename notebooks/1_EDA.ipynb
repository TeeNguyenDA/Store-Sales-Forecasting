{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Store Sales Forecasting\n",
    "\n",
    "### Introduction\n",
    "The data employed in this analysis is sourced from the 'Store Sales - Time Series Forecasting' dataset from [Kaggle](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data).\n",
    "\n",
    "In this notebook, we will undertake the task of predicting the future sales for products at the Favorita retail chain in Ecuador. The dataset which has been simplified to encompass a range of variables including specifics of the store and items, promotional activity indicators, and historical sales figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I : EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# from fbprophet import Prophet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set pandas options to display floats without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data files used (simplified versions of the original dataset):\n",
    "1) store_sales_raw\n",
    "2) holidays_events.csv\n",
    "4) stores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "store_sales_df = pd.read_csv(r'../data/store_sales_raw.csv')\n",
    "holidays_df = pd.read_csv(r'../data/holidays_events.csv')\n",
    "store_df = pd.read_csv(r'../data/stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3029400 entries, 0 to 3029399\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   id           int64  \n",
      " 1   date         object \n",
      " 2   store_nbr    int64  \n",
      " 3   family       object \n",
      " 4   sales        float64\n",
      " 5   onpromotion  float64\n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 138.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Print information about the main dataframe called 'store_sales_df'\n",
    "store_sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         350 non-null    object\n",
      " 1   type         350 non-null    object\n",
      " 2   locale       350 non-null    object\n",
      " 3   locale_name  350 non-null    object\n",
      " 4   description  350 non-null    object\n",
      " 5   transferred  350 non-null    bool  \n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print information about holidays & events in a dataframe called 'holidays_df'\n",
    "holidays_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   store_nbr  54 non-null     int64 \n",
      " 1   city       54 non-null     object\n",
      " 2   state      54 non-null     object\n",
      " 3   type       54 non-null     object\n",
      " 4   cluster    54 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print information about the stores in a dataframe called 'store_df'\n",
    "store_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Prepping for Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Datetime for the date column of 'store_sales_df' and 'holidays_df'\n",
    "store_sales_df['date'] = pd.to_datetime(store_sales_df.date)\n",
    "holidays_df['date'] = pd.to_datetime(holidays_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029395</th>\n",
       "      <td>3029395</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029396</th>\n",
       "      <td>3029396</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029397</th>\n",
       "      <td>3029397</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029398</th>\n",
       "      <td>3029398</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029399</th>\n",
       "      <td>3029399</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       date  store_nbr                      family   sales  \\\n",
       "0              0 2013-01-01          1                  AUTOMOTIVE 0.00000   \n",
       "1              1 2013-01-01          1                   BABY CARE 0.00000   \n",
       "2              2 2013-01-01          1                      BEAUTY 0.00000   \n",
       "3              3 2013-01-01          1                   BEVERAGES 0.00000   \n",
       "4              4 2013-01-01          1                       BOOKS 0.00000   \n",
       "...          ...        ...        ...                         ...     ...   \n",
       "3029395  3029395 2017-08-31          9                     POULTRY 1.00000   \n",
       "3029396  3029396 2017-08-31          9              PREPARED FOODS 0.00000   \n",
       "3029397  3029397 2017-08-31          9                     PRODUCE 1.00000   \n",
       "3029398  3029398 2017-08-31          9  SCHOOL AND OFFICE SUPPLIES 9.00000   \n",
       "3029399  3029399 2017-08-31          9                     SEAFOOD 0.00000   \n",
       "\n",
       "         onpromotion  \n",
       "0            0.00000  \n",
       "1            0.00000  \n",
       "2            0.00000  \n",
       "3            0.00000  \n",
       "4            0.00000  \n",
       "...              ...  \n",
       "3029395          NaN  \n",
       "3029396          NaN  \n",
       "3029397          NaN  \n",
       "3029398          NaN  \n",
       "3029399          NaN  \n",
       "\n",
       "[3029400 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000888</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000889</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000890</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000891</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000892</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029395</th>\n",
       "      <td>3029395</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029396</th>\n",
       "      <td>3029396</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029397</th>\n",
       "      <td>3029397</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029398</th>\n",
       "      <td>3029398</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029399</th>\n",
       "      <td>3029399</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       date  store_nbr                      family    sales  \\\n",
       "3000888  3000888 2017-08-16          1                  AUTOMOTIVE  0.00000   \n",
       "3000889  3000889 2017-08-16          1                   BABY CARE  0.00000   \n",
       "3000890  3000890 2017-08-16          1                      BEAUTY  2.00000   \n",
       "3000891  3000891 2017-08-16          1                   BEVERAGES 20.00000   \n",
       "3000892  3000892 2017-08-16          1                       BOOKS  0.00000   \n",
       "...          ...        ...        ...                         ...      ...   \n",
       "3029395  3029395 2017-08-31          9                     POULTRY  1.00000   \n",
       "3029396  3029396 2017-08-31          9              PREPARED FOODS  0.00000   \n",
       "3029397  3029397 2017-08-31          9                     PRODUCE  1.00000   \n",
       "3029398  3029398 2017-08-31          9  SCHOOL AND OFFICE SUPPLIES  9.00000   \n",
       "3029399  3029399 2017-08-31          9                     SEAFOOD  0.00000   \n",
       "\n",
       "         onpromotion  \n",
       "3000888          NaN  \n",
       "3000889          NaN  \n",
       "3000890          NaN  \n",
       "3000891          NaN  \n",
       "3000892          NaN  \n",
       "...              ...  \n",
       "3029395          NaN  \n",
       "3029396          NaN  \n",
       "3029397          NaN  \n",
       "3029398          NaN  \n",
       "3029399          NaN  \n",
       "\n",
       "[28512 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_sales_df.loc[store_sales_df['onpromotion'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do preprocessing and train the forecasting model on the 'store_sales_historical' and use 'store_sales_validation' for validation of our forecast as we don't have a full year of data for 2017. Also, sales forecasting usually take place at the end of the fiscal year and we're usually forecast for the whole year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holidays & Events calendar plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to datetime format\n",
    "holidays_df['date'] = pd.to_datetime(holidays_df['date'])\n",
    "\n",
    "# # Filter the data for the years 2013-2014\n",
    "# holidays_2013_2014 = holidays_df[(holidays_df['date'].dt.year >= 2013) & (holidays_df['date'].dt.year <= 2014)]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.scatterplot(data=holidays_df, x='date', y='description', hue='locale', palette='viridis', marker='o')\n",
    "plt.title('Holidays')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Holiday Description')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Locale', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df.store_nbr.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df.state.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df.city.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stores in each state\n",
    "store_count = store_df.groupby('state').store_nbr.nunique().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18,10))\n",
    "sns.barplot(data=store_count, x='state', y='store_nbr', palette='tab20')\n",
    "\n",
    "# Setting whole number units for y-axis\n",
    "max_stores = store_count['store_nbr'].max()\n",
    "plt.yticks(list(range(0, max_stores + 1)))\n",
    "\n",
    "plt.title('Number of Stores per State')\n",
    "plt.ylabel('Number of Stores')\n",
    "plt.xlabel('State')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stores in each city with state as hue\n",
    "store_count = store_df.groupby(['city', 'state']).store_nbr.nunique().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Create a custom color palette to match with the state color map above\n",
    "custom_palette = {\n",
    "    'Pichincha': '#1f77b4',\n",
    "    'Guayas': '#aec7e8',\n",
    "    'Azuay': '#ff7f0e',\n",
    "    'Manabi': '#ffbb78',\n",
    "    'Santo Domingo de los Tsachilas': '#2ca02c',\n",
    "    'Cotopaxi': '#98df8a',\n",
    "    'El Oro': '#d62728',\n",
    "    'Los Rios': '#ff9896',\n",
    "    'Tungurahua': '#9467bd',\n",
    "    'Bolivar': '#c5b0d5',\n",
    "    'Chimborazo': '#8c564b',\n",
    "    'Esmeraldas': '#c49c94',\n",
    "    'Imbabura': '#e377c2',\n",
    "    'Loja': '#f7b6d2',\n",
    "    'Pastaza': '#7f7f7f',\n",
    "    'Santa Elena': '#c7c7c7'\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18,10))\n",
    "sns.barplot(data=store_count, x='city', y='store_nbr', hue='state', palette=custom_palette, dodge=False, width=0.8)\n",
    "\n",
    "# Setting whole number units for y-axis\n",
    "max_stores = store_count['store_nbr'].max()\n",
    "plt.yticks(list(range(0, max_stores + 1)))\n",
    "\n",
    "plt.title('Number of Stores per City')\n",
    "plt.ylabel('Number of Stores')\n",
    "plt.xlabel('City')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Move legend to the top right corner\n",
    "plt.legend(title='State', loc='upper right', bbox_to_anchor=(1, 1.05))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep on store_sales_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw dataframe\n",
    "store_sales_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw dataframe\n",
    "store_sales_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding features to complete dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more datetime column \n",
    "store_sales_df['year'] = store_sales_df['date'].dt.year\n",
    "store_sales_df['month'] = store_sales_df['date'].dt.month\n",
    "store_sales_df['week'] = store_sales_df['date'].dt.isocalendar().week.astype(int)\n",
    "store_sales_df['day_name'] = store_sales_df['date'].dt.day_of_week\n",
    "store_sales_df['day_name'] = store_sales_df['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_historical = store_sales_df[store_sales_df['date'] < '2017-01-01']\n",
    "store_sales_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_validation = store_sales_df[store_sales_df['date'] >= '2017-01-01']\n",
    "store_sales_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot per sale for all historical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(store_sales_historical.date, store_sales_historical.sales, color='steelblue')\n",
    "\n",
    "# Setting the x-axis scale to be in year units\n",
    "years = mdates.YearLocator()   # Every year\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "plt.gca().xaxis.set_major_locator(years)\n",
    "plt.gca().xaxis.set_major_formatter(years_fmt)\n",
    "plt.title('Sales trend during 2013-2017')\n",
    "plt.ylabel('Sales')\n",
    "plt.xlabel('Year')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time Span: The graph covers a time span from 2013 to 2017. Data from 2013-01-01 to 2017-08-15. 2017 data only covers until 15th of August (only half of the month).\n",
    "* Overall Trend: The data seems to display a relatively stable trend of sales with periodic spikes. The frequency of these spikes suggests some form of cyclical or seasonal trend.\n",
    "* Peaks: There are significant peaks in the end part of the year, from the 2013 - 2017 data.\n",
    "* Fluctuations: The year of 2016 have much more pronounced fluctuations of sales compared to other, which suggests a volatility during those years probably impacted by the external environment. The cause might be a magnitude 7.8 earthquake struck Ecuador on April 16, 2016. \"People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake\" ([Source](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data)). If we compare the sales with the Holiday & Events calendar, there's an unprecedented national event windows called \"Terremoto Manabi\" that extended to \"Terremoto Manabi +30\" for 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall sales trend by date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by date\n",
    "date_sales = store_sales_historical.groupby('date')['sales'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(date_sales.date, date_sales.sales, color='steelblue')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.gca().xaxis.set_major_locator(years)\n",
    "plt.gca().xaxis.set_major_formatter(years_fmt)\n",
    "plt.title('Avg Sales by Date')\n",
    "plt.ylabel('Avg Sales')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fluctuations: The historical sales data exhibits periodic spikes, suggesting possible seasonal influences or promotional events that lead to peaks in sales. Starting from 2014 towards 2017, there is a noticeable increase in the frequency and height of the spikes. This could indicate growing customer interest, more successful marketing campaigns, or the expansion of the business.\n",
    "* Overall trend: The sales figures from 2013 to 2017 show an upward trend. The baseline (lowest points between the peaks) also appears to be increasing over time, indicating a steady growth in sales.\n",
    "* 2015: There's a noticeable change in the year 2015 where the sales figures seem to become denser with more frequent fluctuations.\n",
    "* 2016: Towards the end of the chart, in 2017, there is a clear upward trend with sales figures consistently staying on the higher side. The impact of the Terremoto de Ecuador de 2016 earthquake might have impacted this trend starting from April 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales by Year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by year\n",
    "yearly_sales = store_sales_historical.groupby('year')['sales'].sum().reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=yearly_sales, x='year', y='sales', palette='tab20')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title('Total Sales by Year')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a consistent growth in total sales from 2013 to 2016. Each year experienced higher sales than the previous year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales by Month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averge sales by month\n",
    "monthly_sales = store_sales_historical.groupby('month')['sales'].mean().reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=monthly_sales, x='month', y='sales', palette='tab20')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title('Avg Sales by Month')\n",
    "plt.ylabel('Avg Sales')\n",
    "plt.xlabel('Month')\n",
    "plt.xticks(ticks=range(12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The months with the lowest average sales are February and September. Sales then begin to rise again in the last quarter of the year, from September, October to December."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales by Day of the Week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of days in order\n",
    "days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Average sales by day of the week\n",
    "daily_sales = store_sales_df.groupby('day_name')['sales'].mean().reindex(days_order).reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=daily_sales, x='day_name', y='sales', order=days_order, palette='tab20')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title('Avg Sales by Day of the Week')\n",
    "plt.ylabel('Avg Sales')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a noticeable trend in the average sales throughout the week. Sales start relatively lower on Monday through Wednesday, see a dip on Thursday, and starting to pick up from Friday through Sunday. Weekends such as Saturday and Sunday are the most popular shopping day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'family' and calculate the average sales\n",
    "avg_sales = store_sales_historical.groupby('family')['sales'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Take the top 20 product families\n",
    "top_20_families = avg_sales.head(20)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 7))\n",
    "top_20_families.plot(kind='bar', color='steelblue')\n",
    "plt.title('Average Sales per Top 20 Product Family')\n",
    "plt.ylabel('Average Sales')\n",
    "plt.xlabel('Product Family')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The 'GROCERY I' product family has the highest average sales by a significant margin, second by 'BEVERAGES' which combined exceeding all other product families by a big distance. . The top 5 product families by average sales are 'GROCERY I', 'BEVERAGES', 'PRODUCE', 'CLEANING', and 'DAIRY'.\n",
    "* 'BREAD/BAKERY', 'POULTRY', 'MEATS', 'PERSONAL CARE', 'DELI', 'EGGS', 'FROZEN FOODS', 'HOME CARE', 'PREPARED FOODS', 'LIQUOR,WINE,BEER' belong to the low to moderate group of product family sales. There's a noticeable drop for the rest of the product families after the top 15.\n",
    "* The top 20 product families cover a broad range of consumer goods, from grocery ('GROCERY I', 'GROCERY II'), essential food item (like 'DAIRY', 'POULTRY', 'EGGS'), beverages, meat, produce & frozen food, cleaning, health & beauty care to more niche categories ('CELEBRATION', 'HOME AND KITCHEN')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'year' and sum the 'onpromotion' column\n",
    "yearly_promotions = store_sales_historical.groupby('year')['onpromotion'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15,8))\n",
    "yearly_promotions.plot(kind='bar', color='steelblue')\n",
    "plt.title('Avg Promotion by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Avg Promotion')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'year' and average the 'sales' column\n",
    "yearly_sales = store_sales_historical.groupby('year')['sales'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15,8))\n",
    "yearly_sales.plot(kind='bar', color='steelblue')\n",
    "plt.title('Avg Sales by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Avg Sales')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Avg. Promotion vs. Avg. Sales per year:\n",
    "\n",
    "* Promotions Trend: 2013 saw a minimal average promotion, almost close to zero, while there's a slight increase in promotions in 2014 but was still relatively low. The average number of promotions quickly increase from 2015 to 2016.\n",
    "* Sales Trend: In 2013, the average sales were just above 200 almost without any promotion. The average sales increased by nearly one-third in 2014, approaching the 300 mark with around 1 promo on average per year. Although there are nearly 2 promotions on average per year in 2015, the year 2015 experienced a slower growth compared to 2014. The average number of promotions skyrocketed to almost 5 per year in 2016, whereas the highest average sales were also recorded in 2016, surpassing 400. \n",
    "* The rise in average sales from 2013 to 2014 might correspond to promotions, but can also indicates that other factors not captured in our charts.\n",
    "* 2016 had both the highest promotions and sales, which overlaps with the earthquake event in 2016. The promotional strategy and external factors benefiting the business sales that year don't necessarily indicate positive impacts on profits. The grocery chain might receive funding from the government or investing more on CSR after the dreaded event. We'll investigate about that right after with the comparison between the average promotion and sales per month of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'year' and 'month' and then compute the mean of the 'onpromotion' column\n",
    "year_month_promotions = store_sales_historical.groupby(['year', 'month'])['onpromotion'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15,8))\n",
    "year_month_promotions.plot(kind='bar', color='steelblue')\n",
    "plt.title('Avg Promotion by Year and Month')\n",
    "plt.xlabel('Year, Month')\n",
    "plt.ylabel('Avg Promotion')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'year' and 'month' and then compute the mean of the 'sales' column\n",
    "year_month_sales = store_sales_historical.groupby(['year', 'month'])['sales'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15,8))\n",
    "year_month_sales.plot(kind='bar', color='steelblue')\n",
    "plt.title('Avg Sales by Year and Month')\n",
    "plt.xlabel('Year, Month')\n",
    "plt.ylabel('Avg Sales')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Avg. Promotion vs. Avg. Sales per month of the year:\n",
    "\n",
    "* Avg Promotion by Year and Month: The average promotion remained relatively low from the beginning of 2013 up to mid-2015. Starting from late 2015, there's a noticeable upward trend in the average promotion, with the values increasing steadily. There is a clear trend of the business focusing on upping the average number of promotions from September to December every year. It's the period where the demand for buying grocery increase vastly with Christmas and New Year, which could also be attributed to holiday promotions or year-end sales drives.\n",
    "* Avg Sales by Year and Month: There seems to correlation between promotions and sales, especially in 2014 and 2016. There's no clear trend in 2015, with some peaks and troughs but not much linked to promotion. That could come from other external factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by week and get the mean of sales\n",
    "# weekly_sales = store_sales_historical.groupby(store_sales_historical['week']).agg({'sales':'mean'}).reset_index()\n",
    "# weekly_sales.columns = ['week', 'sales']\n",
    "\n",
    "# # Group by month and get the mean of sales\n",
    "# monthly_sales = store_sales_historical.groupby(store_sales_historical['month']).agg({'sales':'mean'}).reset_index()\n",
    "# monthly_sales.columns = ['month', 'sales']\n",
    "\n",
    "# # Plotting\n",
    "# fig, axes = plt.subplots(2, 1, figsize=(18, 10))\n",
    "\n",
    "# # Weekly Sales\n",
    "# sns.scatterplot(x='week', y='sales', data=weekly_sales, ax=axes[0], linestyle='-', marker='o')\n",
    "# sns.regplot(x='week', y='sales', data=weekly_sales, ax=axes[0])\n",
    "# axes[0].set_title('Avg Sales (grouped by week)')\n",
    "# axes[0].set_xlabel('week')\n",
    "# axes[0].set_ylabel('sales')\n",
    "# axes[0].set_xticks(range(1, 54))  # Set x-ticks to display each week from 1 to 53\n",
    "# axes[0].ticklabel_format(style='plain', axis='y')\n",
    "# axes[0].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# # Monthly Sales\n",
    "# sns.scatterplot(x='month', y='sales', data=monthly_sales, ax=axes[1], linestyle='-', marker='o')\n",
    "# sns.regplot(x='month', y='sales', data=monthly_sales, ax=axes[1])\n",
    "# axes[1].set_title('Avg Sales (grouped by month)')\n",
    "# axes[1].set_xlabel('month')\n",
    "# axes[1].set_ylabel('sales')\n",
    "# axes[1].set_xticks(range(1, 13))  # Set x-ticks to display each unique month\n",
    "# axes[1].ticklabel_format(style='plain', axis='y')\n",
    "# axes[1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_sales object created above\n",
    "date_sales2 = store_sales_historical.groupby(['date'])['sales'].agg(['sum']).reset_index().rename(columns={'sum': 'sales'})\n",
    "date_sales2.set_index('date', inplace=True)\n",
    "date_sales2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We'll choose to predict by month???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The line of code y = tseries['Sales'].resample('MS').mean() performs the following actions:\n",
    "\n",
    "tseries['Sales']: This selects the 'Sales' column from the tseries dataframe.\n",
    "\n",
    ".resample('MS'): This resamples the time series data based on a specific frequency. The 'MS' frequency string stands for \"Month Start\". When you resample data with this frequency, it means you're grouping the data into intervals that start on the first day of each month.\n",
    "\n",
    ".mean(): After resampling the data into monthly intervals, this calculates the mean (average) of the 'Sales' values within each of those monthly intervals.\n",
    "\n",
    "The result, y, is a pandas Series where the index consists of the first day of each month and the values are the average 'Sales' for each of those months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pylab import rcParams\n",
    "\n",
    "# Extracting sales as a time series\n",
    "# y = date_sales2['sales'].resample('MS').mean()\n",
    "y = date_sales2['sales'].resample('MS').sum()\n",
    "\n",
    "# Setting the figure size\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "\n",
    "# Decomposing the time series\n",
    "decomposition = seasonal_decompose(y, model='additive')\n",
    "\n",
    "# Plotting the decomposition\n",
    "fig = decomposition.plot()\n",
    "\n",
    "# Generate a list of all months from 2013 to end of 2016\n",
    "all_months = pd.date_range(start='2013-01-01', end='2016-12-31', freq='MS')\n",
    "\n",
    "# Set these dates as x-ticks and format the x-tick labels to show month and year\n",
    "plt.xticks(all_months, all_months.strftime('%b %Y'), rotation=90, fontsize=10)\n",
    "\n",
    "plt.tight_layout()  # Adjust the layout for better appearance\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an increasing trend in sales from 2013 to 2016.\n",
    "Clear annual seasonality exists, with certain months consistently showing higher or lower sales.\n",
    "Some unusual residuals are observed which might need further investigation to identify possible anomalies or events influencing sales in those months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# differencing technique for transdformin non stationary to stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_historical_grouped = store_sales_historical.groupby('date')['sales'].sum().reset_index()\n",
    "store_sales_historical_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, title=''):\n",
    "    \"\"\"\n",
    "    Pass in a time series and an optional title, returns an ADF report\n",
    "    \"\"\"\n",
    "    print('Augmented Dickey-Fuller Test: {}'.format(title))\n",
    "    # .dropna() handles differenced data\n",
    "    result = adfuller(series.dropna(),autolag='AIC') \n",
    "    \n",
    "    labels = ['ADF test statistic','p-value','# lags used','# observations']\n",
    "    out = pd.Series(result[0:4],index=labels)\n",
    "\n",
    "    for key,val in result[4].items():\n",
    "        out['critical value ({})'.format(key)]=val\n",
    "        \n",
    "    # .to_string() removes the line \"dtype: float64\"\n",
    "    print(out.to_string())          \n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Strong evidence against the null hypothesis\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"Data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak evidence against the null hypothesis\")\n",
    "        print(\"Fail to reject the null hypothesis\")\n",
    "        print(\"Data has a unit root and is non-stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregating the Time Series to a monthly scaled index\n",
    "y2 = store_sales_historical_grouped[['date','sales']].copy()\n",
    "y2.set_index('date', inplace=True)\n",
    "y2.index = pd.to_datetime(y2.index)\n",
    "y2 = y2.resample('1M').sum()\n",
    "        \n",
    "adf_test(y2['sales'],title='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is not stationary but we want to use a model such as ARIMA (that requires this characteristic), the data has to be transformed. The two most common methods to transform series into stationarity ones are:\n",
    "\n",
    "Transformation: e.g. log or square root to stabilize non-constant variance\n",
    "Differencing: subtracts the current value from the previous\n",
    "Hereafter, we are going to transform sales trend from non-stationarity to stationarity using diff method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# decomposition2 = seasonal_decompose(y2, model='additive')\n",
    "\n",
    "# fig = plt.figure(figsize=(22,8))\n",
    "# decomposition2.trend.diff().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_historical_grouped['diff_sales'] = store_sales_historical_grouped['sales'].diff()\n",
    "store_sales_historical_grouped = store_sales_historical_grouped.dropna()\n",
    "store_sales_historical_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA model\n",
    "\n",
    "auto_arima() function will be used to automatically select the best parameters for an ARIMA model. It takes several parameters to set a range of values for p, d, q, P, D, Q that the function will explore. For example, start_p=1, start_q=1 and max_p=3, max_q=3 are set as the range for p and q.\n",
    "The auto_arima() model will use the stepwise=True option to fit the model iteratively and improve the model at each step.\n",
    "The fitted model is then stored in the model_fit variable and the summary of the model is printed.\n",
    "Finally, the code uses the predict() function of the fitted model to forecast the next 'n' periods of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pmdarima --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create function to group by the called frequency (W = week, M = month, Y = year)\n",
    "# def grouped(df, key, freq, col):\n",
    "#     \"\"\" GROUP DATA WITH CERTAIN FREQUENCY \"\"\"\n",
    "#     df_grouped = df.groupby([pd.Grouper(key=key, freq=freq)]).agg(mean = (col, 'mean'))\n",
    "#     df_grouped = df_grouped.reset_index()\n",
    "#     return df_grouped\n",
    "\n",
    "# df_grouped_trans_m = grouped(df_trans, 'date', 'M', 'transactions')\n",
    "# df_grouped_trans_w = grouped(df_trans, 'date', 'W', 'transactions')\n",
    "# df_grouped_trans_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run combinations of ARIMA(p,d,q)\n",
    "# model_fit = auto_arima(store_sales_historical_grouped['diff_sales'],\n",
    "#                        m=12,\n",
    "#                        d=0,\n",
    "#                        D=0,\n",
    "#                        max_order=None,                       \n",
    "#                        max_p=7,\n",
    "#                        max_q=7,\n",
    "#                        max_d=2,\n",
    "#                        max_P=4,\n",
    "#                        max_Q=4,\n",
    "#                        max_D=2,\n",
    "#                        maxiter = 50,\n",
    "#                        alpha = 0.05,\n",
    "#                        n_jobs = -1,\n",
    "#                        seasonal=True,\n",
    "#                        trace=True,\n",
    "#                        error_action='ignore',  \n",
    "#                        suppress_warnings=True, \n",
    "#                        stepwise=True\n",
    "#                       )\n",
    "\n",
    "# model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DON'T USE model_fit = auto_arima(store_sales_historical_grouped['diff_sales'] without setting d and D to 0!!!!\n",
    "\n",
    "When you use store_sales_historical_grouped['sales'], the auto_arima function will try to find the optimal order of differencing d and D (for seasonal component) for you. However, when you use store_sales_historical_grouped['diff_sales'] and set d=0 and D=0, you are essentially telling the function that you've already differenced the data and it should not apply any further differencing.\n",
    "\n",
    "If you decide to use store_sales_historical_grouped['sales'], you might want to allow auto_arima to determine the best differencing order by not setting d and D to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.arima.model import ARIMA  # Note: The import location might be different based on your version of statsmodels\n",
    "\n",
    "# # Define the model using the best parameters from auto_arima or any specific order you'd like\n",
    "# model_ARIMA = ARIMA(store_sales_historical_grouped[['date','diff_sales']], order=(3,0,2), seasonal_order=((1,0,1)))  # replace p, d, q with the values you've identified\n",
    "\n",
    "# # Fit the model\n",
    "# results = model_ARIMA.fit()\n",
    "\n",
    "# # Display the results\n",
    "# print(results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_forecast = train.copy()\n",
    "# test_forecast = test.copy()\n",
    "\n",
    "# train_forecast['forecast_ARIMA'] = model_ARIMA.predict()\n",
    "# train_forecast[['mean','forecast_ARIMA']].plot(figsize=(20,8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
